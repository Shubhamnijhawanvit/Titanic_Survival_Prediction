# Titanic_Survival_Prediction
### **🚀 Titanic Survival Prediction**  

Predicting the survival of Titanic passengers using **Machine Learning (Logistic Regression & Deep Learning)** with **data preprocessing, feature engineering, and hyperparameter tuning** to achieve **83.5% accuracy**.  

---

## **📌 Project Overview**  
This project analyzes Titanic passenger data to predict survival outcomes using **Logistic Regression & Deep Learning (MLP with TensorFlow/Keras)**. It includes:  
✅ **EDA (Exploratory Data Analysis)** – Identifying survival trends using Seaborn & Matplotlib.  
✅ **Data Preprocessing** – Handling missing values, encoding categorical variables, and feature scaling.  
✅ **Model Training** – Implementing both **Logistic Regression & Deep Learning** to compare performance.  
✅ **Hyperparameter Tuning** – Optimizing learning rate & optimizers using Weights & Biases (W&B).  
✅ **Model Evaluation** – Achieved **83.5% accuracy** using TensorFlow.  
✅ **Final Prediction & Submission** – Generating survival predictions for Kaggle.  

---

## **📂 Project Structure**  
```
📁 Titanic-Survival-Prediction/
│── 📄 README.md              # Project documentation  
│── 📄 titanic_survival.ipynb # Jupyter Notebook with full implementation  
│── 📄 train.csv              # Training dataset  
│── 📄 test.csv               # Test dataset  
│── 📄 submission.csv         # Predicted survival outcomes  
│── 📁 models/                # Saved models (Logistic Regression & Deep Learning)  
```

---

## **🛠️ Tech Stack & Tools**  
🔹 **Programming Language:** Python  
🔹 **Libraries:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-Learn, TensorFlow, Keras  
🔹 **Experiment Tracking:** Weights & Biases (W&B)  
🔹 **Deployment:** GitHub, Kaggle  

---

## **🚀 Installation & Usage**  
1️⃣ **Clone the Repository:**  
```bash
git clone https://github.com/your-username/Titanic-Survival-Prediction.git
cd Titanic-Survival-Prediction
```
2️⃣ **Install Required Libraries:**  
```bash
pip install -r requirements.txt
```
3️⃣ **Run the Notebook (Google Colab or Jupyter Notebook)**  

---

## **📊 Results & Performance**  
- **Logistic Regression Accuracy:** ~75%  
- **Deep Learning Model Accuracy (MLP):** **83.5%**  
- **Optimized Hyperparameters (Adam, SGD) using W&B**  

---

## **📌 Future Improvements**  
🔹 Implement **Ensemble Models (Random Forest, XGBoost)** for better predictions.  
🔹 Extract more **feature interactions** (e.g., `Title` from `Name`, `FamilySize`).  
🔹 Tune **Deep Learning architecture** (CNN or LSTM for sequence learning).  

---

## **📜 License**  
This project is open-source and available under the **MIT License**.  

---

## **📬 Contact**  
🔹 **GitHub:** [[Your GitHub Profile](https://github.com/your-username)  ](https://github.com/Shubhamnijhawanvit)
🔹 **LinkedIn:** [[Your LinkedIn Profile](https://linkedin.com/in/your-profile)  ](https://www.linkedin.com/in/shubham-nijhawan/)

---

🚀 **If you find this project helpful, feel free to ⭐ star the repository!**  

---

🔥 **Now your GitHub README is well-structured, ATS-optimized, and professional! Let me know if you need refinements!** 🔥
